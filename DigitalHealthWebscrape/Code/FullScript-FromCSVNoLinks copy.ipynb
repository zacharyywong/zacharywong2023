{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75f97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extracts the title, link, and short description of search results on Google \n",
    "\n",
    "#import all libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time, sys, requests, random\n",
    "\n",
    "\n",
    "# import libs, authorize gspread  \n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "google_key_file = '/Users/zacharywong/Documents/ServiceAccountKey-Secret/pelagic-tracker-338302-eaf0e0e671cb.json'\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(google_key_file, scope)\n",
    "gc = gspread.authorize(credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63fc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# paths/baseurls\n",
    "spreadsheet_id = '1vFXonFCyUlEKa1f0s5tvHCKeTek_sAv7rUPYfYss0Qo'\n",
    "companyFilePath = '/Users/zacharywong/github/zacharywong2023/DigitalHealthWebscrape/Misc/Companies/Company Web Scrape Tool - Company Names.csv'\n",
    "driver_path = '/Users/zacharywong/Documents/Work/Portfolio/DigitalHealthWebscrape/chromedriver'\n",
    "pathtoFile = '/Users/zacharywong/github/zacharywong2023/DigitalHealthWebscrape/Results_CSV/'\n",
    "googleurl = 'https://www.google.com/'\n",
    "\n",
    "columnName = 'Company Names (Leave Blank if Using LinkedIn Company Mining)'\n",
    "#ints \n",
    "adjustDenominator = 3\n",
    "maxbackOff = 120\n",
    "maxResult = 1\n",
    "waitTime = 5\n",
    "waitRun = 0.3\n",
    "\n",
    "#bools\n",
    "useURL = False\n",
    "useName = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a761739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait():\n",
    "    pass\n",
    "    global waitRun\n",
    "    sleepTime = waitRun + random.uniform(0, 1)\n",
    "    #print('sleepTime: ', sleepTime)\n",
    "    time.sleep(sleepTime)\n",
    "    waitRun = waitRun*2\n",
    "    #print('waitRun: ', waitRun)\n",
    "    if (waitRun >= maxbackOff):\n",
    "        sys.exit(\"error: read from sheets quota exceeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2780835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: reads in values from DigitalHealthWebscrape google sheet\n",
    "# Need spreadsheet ID and the cell address where the value should be read in \n",
    "# returns the value \n",
    "\n",
    "def readinValue(cellLocation, sheetIndex):\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    worksheet = sh.get_worksheet(sheetIndex)\n",
    "    try:\n",
    "        value = worksheet.acell(cellLocation).value\n",
    "    except:\n",
    "        wait()\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84ee9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCompanies():\n",
    "    #links = []\n",
    "    names = []\n",
    "    df = pd.read_csv(companyFilePath, usecols = [columnName])\n",
    "    df[columnName]=df[columnName].fillna(' ')\n",
    "    #df['Link']=df['Link'].fillna(' ')\n",
    "    names = df[columnName].tolist()\n",
    "    #links = df['Link'].tolist()\n",
    "    print(df)\n",
    "    return names \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6bf564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readKeyWords():\n",
    "    keywords = []\n",
    "    row = 2;\n",
    "    sheetIndex = 1\n",
    "    isDone = False\n",
    "    cellLocationColumn = 'B'\n",
    "    while (isDone == False):\n",
    "        cellLocationKeyWords = cellLocationColumn + str(row)\n",
    "        try:\n",
    "            keyword = readinValue(cellLocationKeyWords, sheetIndex)\n",
    "            keywords.append(keyword)\n",
    "            if(keyword == None):\n",
    "                isDone = True\n",
    "                break\n",
    "            else:\n",
    "                row += 1 \n",
    "        except:\n",
    "            wait()\n",
    "    keywords = keywords[0:len(keywords)-1]\n",
    "    print(keywords)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19843095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCalculateLiklihood():\n",
    "    #print(links, names)\n",
    "    sheetIndex = 1\n",
    "    cellLocationLiklihood = 'A2'\n",
    "    calculateLiklihood = False\n",
    "    try:\n",
    "        calculateLiklihoodInput = readinValue(cellLocationLiklihood, sheetIndex)\n",
    "        if (calculateLiklihoodInput == 'Yes'):\n",
    "            calculateLiklihood = True\n",
    "        else:\n",
    "            calculateLiklihood = False\n",
    "    except:\n",
    "        wait()\n",
    "    return calculateLiklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a706f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInput():\n",
    "    names = readCompanies()\n",
    "    calculateLiklihood = readCalculateLiklihood()\n",
    "    keywords = readKeyWords()\n",
    "    return names, calculateLiklihood, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5294e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract links from 1 page of results\n",
    "def extractLinks(soup):\n",
    "    links = []\n",
    "    #Tags and classes\n",
    "    linksTag = 'div'\n",
    "    linksClass = 'yuRUbf'\n",
    "    linksAttr = 'href'\n",
    "    searchLinks = soup.find_all(linksTag, class_ = linksClass)\n",
    "    for h in searchLinks:\n",
    "        link = h.a.get(linksAttr)\n",
    "        links.append(link)\n",
    "    return links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d4dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTitles(soup):\n",
    "    titles = [] \n",
    "    \n",
    "    titlesClass = 'LC20lb MBeuO DKV0Md'\n",
    "    titlesTag = 'h3'\n",
    "    searchTitles = soup.find_all(titlesTag, class_= titlesClass)\n",
    "    for h in searchTitles:\n",
    "        titles.append(h.text)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa3778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract texts from 1 page of results\n",
    "def extractTexts(soup):\n",
    "    texts = []\n",
    "    textsClass = 'VwiC3b yXK7lf MUxGbd yDYNvb lyLwlc lEBKkf'\n",
    "    textsTag = 'div'\n",
    "    searchText = soup.find_all(textsTag, class_= textsClass)\n",
    "    for h in searchText:\n",
    "        fullText = h.text\n",
    "        try:\n",
    "            splitText = fullText.split('— ', 1)\n",
    "            text = splitText[1]\n",
    "            texts.append(text);\n",
    "        except:\n",
    "            texts.append(fullText)\n",
    "    return texts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670c7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLiklihoods(links, keywords):\n",
    "    #keywords = ['personalized', 'personalization', 'machine-learning', 'AI', 'Artificial Intelligence', '24/7', 'democratizing']\n",
    "    liklihoods = []\n",
    "    detectedWordsAll = []\n",
    "    ignore = ['[document]', 'a', 'article', 'label', 'script', 'style']\n",
    "    liklihoodDenom = len(keywords) - adjustDenominator\n",
    "    for url in links: \n",
    "        detectedWords = []\n",
    "        output = ''\n",
    "        count = 0\n",
    "        liklihood = 0\n",
    "\n",
    "        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        html_page = res.content\n",
    "        soup = bs(html_page, 'html.parser')\n",
    "        #print(\"Encoded method :\" + url + \": \", soup.original_encoding)\n",
    "        text = soup.find_all(text=True)\n",
    "       \n",
    "        for t in text:\n",
    "            if t.parent.name not in ignore:\n",
    "                output += '{} '.format(t)\n",
    "\n",
    "        # analyze the webpage to detect keywords \n",
    "        outputSub = output.split(' ')\n",
    "        #print(outputSub)\n",
    "        for word in keywords: \n",
    "            if (word in outputSub or word.capitalize() in outputSub or word + '\\n' in outputSub):\n",
    "                #print('\"' + word +'\"' + ' detected')\n",
    "                detectedWords.append(word)\n",
    "                count +=1 \n",
    "            #else:\n",
    "                #print(word + ' is not there')\n",
    "        liklihood = round((count / liklihoodDenom), 2)\n",
    "        print(liklihood)\n",
    "        liklihoods.append(liklihood)\n",
    "        detectedWordsAll.append(detectedWords)\n",
    "        #detectedWordsAll = ', '.join(str(keyword) for keyword in detectedWordsAll)\n",
    "    #print(\"detectedWordsAll\", detectedWordsAll)\n",
    "    return liklihoods, detectedWordsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7add298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the keyword you want to search for depending on whether link or name is given\n",
    "# we find the search bar using its name attribute value (q)\n",
    "\n",
    "def searchGoogle(index, namesInput, googleurl, useURL, waitTime, driver):\n",
    "    #print(\"index: \", index)\n",
    "    #print(\"Number of Companies: \" + str((len(linksInput))))\n",
    "    #print(\"links: \", linksInput)\n",
    "    #print(\"names: \", namesInput)\n",
    "    #siteURL = linksInput[index]\n",
    "    #print(\"siteURL: \", siteURL)\n",
    "    websiteName = namesInput[index]\n",
    "    #print(\"websiteName: \", websiteName)\n",
    "    driver.get(googleurl)\n",
    "    searchBar = driver.find_element(By.NAME, 'q')\n",
    "    \n",
    "    # Booleans\n",
    "    #if (siteURL == ' '):\n",
    "    useURL = False; \n",
    "    useName = True; \n",
    "    #else:\n",
    "    #    useURL = True; \n",
    "     #   useName = False; \n",
    "\n",
    "    # first we send our keyword to the search bar followed by the enter # key depending on using URL or website name \n",
    "\n",
    "    if (useURL):\n",
    "        query = \"site: \" + siteURL\n",
    "        print('query: ' + query)\n",
    "        try:\n",
    "            searchBar.send_keys(query)\n",
    "            searchBar.send_keys('\\n')\n",
    "        except Exception as e : \n",
    "            WebDriverWait(driver, waitTime).until(EC.presence_of_element_located((By.NAME, 'q')))\n",
    "            searchBar.send_keys(query)\n",
    "            searchBar.send_keys('\\n')\n",
    "    else:\n",
    "        query = websiteName\n",
    "        print('query: ' + query)\n",
    "        searchBar.send_keys(query)\n",
    "        searchBar.send_keys('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f55f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture links, header, and text\n",
    "#pageInfo is a list of dictionaries for each page with keys/value pairs: header, link, text\n",
    "# extract and load each page of results to pageInfo \n",
    "def parseHTML(driver, calculateLiklihood, keywords, maxResult, pageInfo):\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    links = extractLinks(soup);\n",
    "    texts = extractTexts(soup);\n",
    "    titles = extractTitles(soup);\n",
    "    if (calculateLiklihood):\n",
    "        liklihoods, detectedWordsAll = calculateLiklihoods(links[0:1], keywords)\n",
    "        #print('detectedWordsAllStringForm: ' + str(detectedWordsAll))\n",
    "        #detectedWordsAll = ', '.join([str(keyword) for keyword in detectedWordsAll])\n",
    "        #print(\"detectedWordsAll String Form: \" + detectedWordsAll)\n",
    "        pageInfo = addToPageInfo(titles, links, texts, maxResult, pageInfo, liklihoods, detectedWordsAll)\n",
    "    else:\n",
    "        pageInfo = addToPageInfo(titles, links, texts, maxResult, pageInfo, liklihoods = None, detectedWordsAll = None)\n",
    "\n",
    "    return pageInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768eb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add 1 page of results to pageInfo list\n",
    "def addToPageInfo(titles, links, texts, maxResult, pageInfo, liklihoods, detectedWordsAll):\n",
    "    index = 0;\n",
    "    while (index < maxResult):\n",
    "        #print(\"texts: \", texts)\n",
    "        #print(\"liklihoods: \", liklihoods)\n",
    "        #print(\"length of links list: \" + str((len(linksInput)-1)))\n",
    "        #print(\"links: \", links)\n",
    "        #print(\"titles: \", titles)\n",
    "        #print('detectedWordsAll', detectedWordsAll)\n",
    "        #create new dictionary of each search results' title, link, and text\n",
    "        if (liklihoods == None):\n",
    "            pageInfo.append({\"Title\": titles[index], \"Link\": links[index], \"About\": texts[index]})\n",
    "        else:\n",
    "            #print(\"detectedWordsString: \", detectedWordsAll)\n",
    "            detectedWords = str(detectedWordsAll[index])\n",
    "            pageInfo.append({\"Percentage of Keywords Detected\": liklihoods[index], \"Title\": titles[index], \"Link\": links[index], \"About\": texts[index],  \"Detected KeyWords\": detectedWords})\n",
    "        index += 1\n",
    "    return pageInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aded4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportCSV(df, pathtoFile, fileName):\n",
    "    # convert pageInfo to pandas dataframe and export as csv \n",
    "    df.to_csv(pathtoFile + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d240d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSpreadSheet(df, sheetIndex):\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    worksheet = sh.get_worksheet(sheetIndex)\n",
    "    worksheet.clear()\n",
    "    worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28853f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDeliverables(pageInfo, pathtoFile, fileName, calculateLiklihood):\n",
    "    df = pd.DataFrame(pageInfo)\n",
    "    if (calculateLiklihood):\n",
    "        df = df.sort_values(by = ['Percentage of Keywords Detected'], ascending=False)\n",
    "        df['Percentage of Keywords Detected'] = df['Percentage of Keywords Detected'] * 100\n",
    "    sheetIndex = 3\n",
    "    #print(df.columns.values.tolist())\n",
    "    #print(df.values.tolist())\n",
    "    #print(pageInfo)\n",
    "    exportCSV(df, pathtoFile, fileName)\n",
    "    updateSpreadSheet(df, sheetIndex)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40c073c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runExtraction():\n",
    "    index = 0\n",
    "    namesInput, calculateLiklihood, keywords = readInput()\n",
    "    print(\"Number of Companies: \" + str((len(namesInput))))\n",
    "    fileName = 'CompanyWebScrape_CSV.csv'\n",
    "    # Access chromedriver and determine path \n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service = service)\n",
    "    \n",
    "    # list of dictionaries with key/value pairs: title, link, text\n",
    "    # Contains all information for all search results \n",
    "    pageInfo = []\n",
    "\n",
    "    while (index < len(namesInput)):\n",
    "        searchGoogle(index, namesInput, googleurl, useURL, waitTime, driver)\n",
    "        for page in range(0, 1):\n",
    "            pageInfo = parseHTML(driver, calculateLiklihood, keywords, maxResult, pageInfo)\n",
    "    #print(pageInfo)\n",
    "            index += 1\n",
    "        time.sleep(waitRun)\n",
    "    df = exportDeliverables(pageInfo, pathtoFile, fileName, calculateLiklihood)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29f5bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Company Names (Leave Blank if Using LinkedIn Company Mining)\n",
      "0                     Digital Health Intelligence Ltd          \n",
      "1                         Proteus Digital Health, Inc          \n",
      "2             Digital Health & Care Innovation Centre          \n",
      "3                              Digital Health Forward          \n",
      "4                            Digital Health Coalition          \n",
      "5                    Australian Digital Health Agency          \n",
      "6   Digital Health Institute for Transformation (D...          \n",
      "7                               Digital Health Canada          \n",
      "8                            Digital Health Solutions          \n",
      "9                                         NHS Digital          \n",
      "10                        This Week in Digital Health          \n",
      "11                               Digital Health Today          \n",
      "12                      Global Digital Health Network          \n",
      "13           UCSF | Health Hub: Digital Health Awards          \n",
      "14                          Thryve Digital Health LLP          \n",
      "15    Australasian Institute of Digital Health (AIDH)          \n",
      "16                 Telemedi - Digital Health Platform          \n",
      "17                            Digital Health Insights          \n",
      "18                     Digital Health Forward Podcast          \n",
      "19                                Digital Health PORT          \n",
      "20                      Digital Health and Care Wales          \n",
      "21                 ARTEXE - Digital Health Architects          \n",
      "22     Digital Health and Innovation Cluster Bulgaria          \n",
      "23                                  Digital Health CT          \n",
      "24                                 TAG Digital Health          \n",
      "25           Brown-Lifespan Center for Digital Health          \n",
      "26  Aga Khan Development Network Digital Health Re...          \n",
      "27                                 Digital Health CRC          \n",
      "28                                 UCM Digital Health          \n",
      "29                          Digital Health Strategies          \n",
      "['personalized', 'personalization', 'machine-learning', 'AI', 'Artificial Intelligence', 'A.I.', 'democratizing', '24/7', 'digital assistant ']\n",
      "Number of Companies: 30\n",
      "query: Digital Health Intelligence Ltd\n",
      "0.0\n",
      "query: Proteus Digital Health, Inc\n",
      "0.0\n",
      "query: Digital Health & Care Innovation Centre\n",
      "0.0\n",
      "query: Digital Health Forward\n",
      "0.33\n",
      "query: Digital Health Coalition\n",
      "0.0\n",
      "query: Australian Digital Health Agency\n",
      "0.0\n",
      "query: Digital Health Institute for Transformation (DHIT)\n",
      "0.0\n",
      "query: Digital Health Canada\n",
      "0.0\n",
      "query: Digital Health Solutions\n",
      "0.0\n",
      "query: NHS Digital\n",
      "0.0\n",
      "query: This Week in Digital Health\n",
      "0.0\n",
      "query: Digital Health Today\n",
      "0.0\n",
      "query: Global Digital Health Network\n",
      "0.0\n",
      "query: UCSF | Health Hub: Digital Health Awards\n",
      "0.0\n",
      "query: Thryve Digital Health LLP\n",
      "0.0\n",
      "query: Australasian Institute of Digital Health (AIDH)\n",
      "0.0\n",
      "query: Telemedi - Digital Health Platform\n",
      "0.0\n",
      "query: Digital Health Insights\n",
      "0.0\n",
      "query: Digital Health Forward Podcast\n",
      "0.33\n",
      "query: Digital Health PORT\n",
      "0.17\n",
      "query: Digital Health and Care Wales\n",
      "0.0\n",
      "query: ARTEXE - Digital Health Architects\n",
      "0.17\n",
      "query: Digital Health and Innovation Cluster Bulgaria\n",
      "0.5\n",
      "query: Digital Health CT\n",
      "0.33\n",
      "query: TAG Digital Health\n",
      "0.0\n",
      "query: Brown-Lifespan Center for Digital Health\n",
      "0.0\n",
      "query: Aga Khan Development Network Digital Health Resource Centre\n",
      "0.0\n",
      "query: Digital Health CRC\n",
      "0.0\n",
      "query: UCM Digital Health\n",
      "0.17\n",
      "query: Digital Health Strategies\n",
      "0.0\n",
      "Time Elapsed:  104.32657790184021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage of Keywords Detected</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>About</th>\n",
       "      <th>Detected KeyWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Be part of the Bulgarian digital health ecosystem</td>\n",
       "      <td>https://dhicluster.bg/?lang=en</td>\n",
       "      <td>Digital health ecosystem works for sustainable...</td>\n",
       "      <td>['personalized', 'AI', '24/7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Digital Health Forward on Apple Podcasts</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/digital-...</td>\n",
       "      <td>Sharing the stories of healthcare leaders, ent...</td>\n",
       "      <td>['personalized', 'AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Digital Health CT Startups | hartfordhealthcar...</td>\n",
       "      <td>https://hartfordhealthcare.org/about-us/innova...</td>\n",
       "      <td>A digital health accelerator has recently been...</td>\n",
       "      <td>['personalized', 'AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Digital Health Forward on Apple Podcasts</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/digital-...</td>\n",
       "      <td>Digital Health Forward Dandi Zhu · Vijay Kedar...</td>\n",
       "      <td>['personalized', 'AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17.0</td>\n",
       "      <td>UCM Digital Health: Digital Front Door Solution</td>\n",
       "      <td>https://www.ucmdigitalhealth.com/</td>\n",
       "      <td>UCM Digital Health delivers an end-to-end heal...</td>\n",
       "      <td>['24/7']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percentage of Keywords Detected  \\\n",
       "22                             50.0   \n",
       "3                              33.0   \n",
       "23                             33.0   \n",
       "18                             33.0   \n",
       "28                             17.0   \n",
       "\n",
       "                                                Title  \\\n",
       "22  Be part of the Bulgarian digital health ecosystem   \n",
       "3            Digital Health Forward on Apple Podcasts   \n",
       "23  Digital Health CT Startups | hartfordhealthcar...   \n",
       "18           Digital Health Forward on Apple Podcasts   \n",
       "28    UCM Digital Health: Digital Front Door Solution   \n",
       "\n",
       "                                                 Link  \\\n",
       "22                     https://dhicluster.bg/?lang=en   \n",
       "3   https://podcasts.apple.com/us/podcast/digital-...   \n",
       "23  https://hartfordhealthcare.org/about-us/innova...   \n",
       "18  https://podcasts.apple.com/us/podcast/digital-...   \n",
       "28                  https://www.ucmdigitalhealth.com/   \n",
       "\n",
       "                                                About  \\\n",
       "22  Digital health ecosystem works for sustainable...   \n",
       "3   Sharing the stories of healthcare leaders, ent...   \n",
       "23  A digital health accelerator has recently been...   \n",
       "18  Digital Health Forward Dandi Zhu · Vijay Kedar...   \n",
       "28  UCM Digital Health delivers an end-to-end heal...   \n",
       "\n",
       "                 Detected KeyWords  \n",
       "22  ['personalized', 'AI', '24/7']  \n",
       "3           ['personalized', 'AI']  \n",
       "23          ['personalized', 'AI']  \n",
       "18          ['personalized', 'AI']  \n",
       "28                        ['24/7']  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the script \n",
    "# implement exponential backoff algorithm to prevent exceeding read quota from sheets\n",
    "startTime = time.time()\n",
    "df = runExtraction()\n",
    "endTime = time.time()\n",
    "timeElapsed = endTime - startTime\n",
    "print('Time Elapsed: ', timeElapsed)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65104f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
